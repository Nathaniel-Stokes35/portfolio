{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Mineral Processing and Recovery Machine Model</h1>\n",
    "<h2>Introduction</h2>\n",
    "<p>&nbsp;&nbsp;&nbsp;&nbsp;In this analysis, I will explore and preprocess the datasets, aiming to identify important features and patterns that will inform a machine learning model. The data is already split into training, test, and \"full\" datasets, which will be used to train and evaluate the model. This is a regression task, where the goal is to predict metal concentrate values based on the collected sample data over time.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, make_scorer\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smape(y_true, y_pred):\n",
    "    denominator = (np.abs(y_true) + np.abs(y_pred)) / 2\n",
    "    diff = np.abs(y_true - y_pred) / denominator\n",
    "    return np.mean(diff) * 100\n",
    "\n",
    "smape_scorer = make_scorer(smape, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Preprocessing and Preliminary Analysis</h2>\n",
    "<ol>\n",
    "    <li>Load and display the datasets to understand the structure and content.</li>\n",
    "    <li>Examine the Datasets to better understand key features, and how to properly handle any missing data</li>\n",
    "    <li>Clean the data by imputing missing values using the mean of the training set, ensuring no data leakage.</li>\n",
    "</ol>\n",
    "<h3>Preparing the Data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "train_df = pd.read_csv('/datasets/gold_recovery_train.csv')\n",
    "test_df = pd.read_csv('/datasets/gold_recovery_test.csv')\n",
    "full_df = pd.read_csv('/datasets/gold_recovery_full.csv')\n",
    "\n",
    "# Display the first few rows to get an overview\n",
    "print(\"Training Data Preview:\")\n",
    "display(train_df)\n",
    "print(f\"{os.linesep}Test Data Preview:\")\n",
    "display(test_df.head())\n",
    "print(f\"{os.linesep}Full Data Preview:\")\n",
    "display(full_df.head())\n",
    "\n",
    "# Check the columns (features) in each dataset\n",
    "print(f\"{os.linesep}Training Set Columns:\", train_df.columns)\n",
    "print(f\"{os.linesep}Test Set Columns:\", test_df.columns)\n",
    "print(f\"{os.linesep}Full Set Columns:\", full_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(train_df.describe())\n",
    "print(f'{os.linesep}Missing Values in Training Dataset: ')\n",
    "display(train_df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "numerical_columns = train_df.select_dtypes(include=['int64', 'float64']).columns\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "imputer.fit(train_df[numerical_columns]) # Training Imputer on Training set only to prevent \"leakage\"\n",
    "\n",
    "# Handeling missing columns in the Test Set\n",
    "common_columns = train_df.columns.intersection(test_df.columns).intersection(full_df.columns)\n",
    "missing_in_test = train_df.columns.difference(test_df.columns)\n",
    "\n",
    "print('Missing Columns from Test DataSet:')\n",
    "for col in missing_in_test:\n",
    "    test_df[col] = np.nan\n",
    "    print(col, ' | ', test_df[col].dtype)\n",
    "\n",
    "train_df[numerical_columns] = imputer.transform(train_df[numerical_columns]) # Transforming all the datasets\n",
    "test_df[numerical_columns] = imputer.transform(test_df[numerical_columns]) # for consistency\n",
    "full_df[numerical_columns] = imputer.transform(full_df[numerical_columns])\n",
    "\n",
    "print(f'{os.linesep}Count of different rows for recovery calculations: ')\n",
    "print('Rougher.Output.Recovery: ', train_df['rougher.output.recovery'].count())\n",
    "print('Rougher.Input.Feed_AU: ', train_df['rougher.input.feed_au'].count())\n",
    "print('Rougher.Output.Concentrate_AU: ', train_df['rougher.output.concentrate_au'].count())\n",
    "print(f'{os.linesep}Null Values for Recovery Calculation Variables: ')\n",
    "print('Rougher.Output.Recovery: ', train_df['rougher.output.recovery'].isna().sum())\n",
    "print('Rougher.Input.Feed_AU: ', train_df['rougher.input.feed_au'].isna().sum())\n",
    "print('Rougher.Output.Concentrate_AU: ', train_df['rougher.output.concentrate_au'].isna().sum())\n",
    "\n",
    "print(f'{os.linesep}Missing Values from the Entire Training DataFrame:')\n",
    "display(train_df.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Data\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;The missing columns from the test dataset can be grouped into three major categories: **Concentrate and Tail Data**, **Recovery Data**, and **Ratio and Calculation Data**. Below is an enhanced analysis of the missing features, their significance to the model, and the potential impact of their absence.\n",
    "\n",
    "#### **Concentrate and Tail Data** (e.g., `rougher.output.concentrate_ag`, `final.output.tail_au`)\n",
    "   - **Columns**: \n",
    "     - `final.output.concentrate_ag` (float64)\n",
    "     - `primary_cleaner.output.concentrate_au` (float64)\n",
    "     - `rougher.output.tail_au` (float64), etc.\n",
    "   - **Significance**: These columns represent the amounts of various metals (e.g., gold, silver, lead) extracted or left behind during different stages of the purification process. These features provide critical information about how effectively the different processing stages are recovering valuable metals.\n",
    "   - **Implications**: Missing concentrate and tail data could severely limit the model's ability to evaluate and compare the effectiveness of each stage in terms of material extraction and waste. Without this data, the model may not fully understand how well each process contributes to the overall recovery, potentially affecting the accuracy of its predictions for recovery efficiency.\n",
    "   - **Mitigation**: \n",
    "     - **Imputation**: The missing values in concentrate and tail columns could be imputed based on the relationships with other available features, such as the feed metal content or other stage-specific data. For example, a regression model could be used to predict missing concentrate values based on other available features.\n",
    "     - **Feature Engineering**: New features could be engineered using available columns, such as combining concentrate and tail data with other stage-related features to approximate missing values.\n",
    "\n",
    "#### **Recovery Data** (e.g., `rougher.output.recovery`, `primary_cleaner.output.recovery`)\n",
    "   - **Columns**:\n",
    "     - `rougher.output.recovery` (float64)\n",
    "     - `final.output.recovery` (float64)\n",
    "   - **Significance**: Recovery data is a key metric that quantifies the efficiency of each processing stage in terms of the amount of valuable metal recovered. It is a direct indicator of process effectiveness and essential for optimizing the purification steps.\n",
    "   - **Implications**: Without recovery data, the model will struggle to assess how well each stage is performing. This will make it difficult to optimize the extraction process, leading to potentially inaccurate predictions. Recovery is a critical output, and its absence could result in the model missing key insights into the process efficiency.\n",
    "   - **Mitigation**:\n",
    "     - **Imputation**: If recovery data is missing for certain stages, it could be estimated using other available features or through statistical methods, such as imputation based on the relationship with concentrate or tail data.\n",
    "     - **Alternative Metrics**: If recovery data is completely unavailable, alternative metrics could be derived, such as using feed-to-concentrate ratios, to estimate recovery indirectly.\n",
    "\n",
    "#### **Ratio and Calculation Data** (e.g., `rougher.calculation.au_pb_ratio`)\n",
    "   - **Columns**:\n",
    "     - `rougher.calculation.au_pb_ratio` (float64)\n",
    "     - `rougher.calculation.floatbank10_sulfate_to_au_feed` (float64)\n",
    "   - **Significance**: These columns provide important ratios and calculations that capture the interactions between different process variables, such as the relationship between sulfur content and metal recovery or the ratio of gold to lead in the ore feed. These features are essential for understanding the chemical and physical dynamics of the extraction process.\n",
    "   - **Implications**: Missing these ratios could prevent the model from accurately capturing important relationships between key process variables. This could limit its ability to predict recovery outcomes under different process conditions, especially when the interactions between multiple variables drive recovery efficiency.\n",
    "   - **Mitigation**:\n",
    "     - **Feature Engineering**: Some of these ratios can be recomputed using available data. For example, the `au_pb_ratio` could be calculated by dividing the `au_concentrate` by `pb_concentrate`. Alternatively, if the data is partially available, missing values could be estimated using similar variables or imputation methods.\n",
    "     - **Model Flexibility**: The model might also be retrained without these ratios if they are deemed non-essential, but this could impact model performance and interpretability.\n",
    "\n",
    "### Summary of Missing Data Impacts:\n",
    "Overall, the missing columns are critical for understanding the stages of the extraction process and for making accurate predictions of recovery efficiency. The absence of these features could result in a model that fails to capture important interactions between process variables or assess the true effectiveness of purification stages. Depending on the type and quantity of missing data, various strategies such as imputation, feature engineering, or model adaptation can be employed to mitigate the negative impact and enhance the model's predictive capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = train_df['rougher.output.concentrate_au']\n",
    "F = train_df['rougher.input.feed_au']\n",
    "T = train_df['rougher.output.tail_au'] \n",
    "\n",
    "train_df['calculated_recovery'] = np.where(\n",
    "    (F * (C - T)) != 0,\n",
    "    (C * (F - T)) / (F * (C - T)) * 100,\n",
    "    0 # Handling Infinite cases as 0\n",
    ")\n",
    "train_df['calculated_recovery'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Q1 = train_df['calculated_recovery'].quantile(0.25)\n",
    "Q3 = train_df['calculated_recovery'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "train_df['calculated_recovery'] = np.clip(\n",
    "    train_df['calculated_recovery'],\n",
    "    Q1 - 1.5 * IQR,\n",
    "    Q3 + 1.5 * IQR\n",
    ")\n",
    "\n",
    "total_con_rough = train_df[['rougher.output.concentrate_ag', 'rougher.output.concentrate_au', \n",
    "                                        'rougher.output.concentrate_pb']].sum(axis=1)\n",
    "total_con_cleaner = train_df[['primary_cleaner.output.concentrate_ag', \n",
    "                                                'primary_cleaner.output.concentrate_au', \n",
    "                                                'primary_cleaner.output.concentrate_pb']].sum(axis=1)\n",
    "\n",
    "# Combine the concentration data for analysis\n",
    "total_con = pd.concat([total_con_rough, total_con_cleaner], axis=1)\n",
    "total_con.columns = ['Rougher', 'Primary Cleaner']\n",
    "\n",
    "# Perform IQR anomaly detection\n",
    "Q1_rough = total_con['Rougher'].quantile(0.25)\n",
    "Q3_rough = total_con['Rougher'].quantile(0.75)\n",
    "IQR_rough = Q3_rough - Q1_rough\n",
    "\n",
    "total_con['Rougher'] = np.clip(total_con['Rougher'], \n",
    "                                Q1_rough - 1.5 * IQR_rough, \n",
    "                                Q3_rough + 1.5 * IQR_rough)\n",
    "\n",
    "Q1_cleaner = total_con['Primary Cleaner'].quantile(0.25)\n",
    "Q3_cleaner = total_con['Primary Cleaner'].quantile(0.75)\n",
    "IQR_cleaner = Q3_cleaner - Q1_cleaner\n",
    "\n",
    "total_con['Primary Cleaner'] = np.clip(total_con['Primary Cleaner'], \n",
    "                                                  Q1_cleaner - 1.5 * IQR_cleaner, \n",
    "                                                  Q3_cleaner + 1.5 * IQR_cleaner)\n",
    "\n",
    "# Calculate MAE between calculated recovery and provided recovery\n",
    "mae_recovery = mean_absolute_error(train_df['rougher.output.recovery'], train_df['calculated_recovery'])\n",
    "\n",
    "print(f\"MAE between calculated and provided recovery: {mae_recovery}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Comprehensive Study of Total Concentrations</h3>\n",
    "<p>&nbsp;&nbsp;&nbsp;&nbsp;In order to ensure the quality and consistency of the data, a detailed study of the total concentrations of valuable metals across all purification stages was conducted. This analysis is critical for identifying any outliers or anomalies that may affect the accuracy of model predictions. By examining total concentrations, we can identify any potential data quality issues that may arise during the purification process.</p>\n",
    "\n",
    "<h4>Total Concentration Calculation</h4>\n",
    "<p>&nbsp;&nbsp;&nbsp;&nbsp;Total concentrations for each stage were calculated by summing the concentrate values for the relevant metals (e.g., gold, silver, lead) at each purification stage. The stages analyzed include the rougher, primary cleaner, and final output. These totals represent the total amount of valuable metals recovered at each stage.</p>\n",
    "\n",
    "<p>&nbsp;&nbsp;&nbsp;&nbsp;For example, the total concentration for the rougher stage was calculated as:</p>\n",
    "<pre>\n",
    "total_con_rough = train_df[['rougher.output.concentrate_ag', 'rougher.output.concentrate_au', 'rougher.output.concentrate_pb']].sum(axis=1)\n",
    "</pre>\n",
    "\n",
    "<p>&nbsp;&nbsp;&nbsp;&nbsp;Similarly, the total concentrations for other stages, such as the primary cleaner and final output, were calculated.</p>\n",
    "\n",
    "<h4>Anomaly Detection: IQR Method</h4>\n",
    "<p>&nbsp;&nbsp;&nbsp;&nbsp;To ensure the accuracy of the data, we implemented the Interquartile Range (IQR) method to identify any anomalies in the total concentration values. The IQR method detects outliers by identifying values that lie outside the range defined by the first and third quartiles (Q1 and Q3).</p>\n",
    "\n",
    "<p>&nbsp;&nbsp;&nbsp;&nbsp;Here’s how anomalies were detected for the rougher and primary cleaner stages:</p>\n",
    "<pre>\n",
    "Q1_rough = total_con['Rougher'].quantile(0.25)\n",
    "Q3_rough = total_con['Rougher'].quantile(0.75)\n",
    "IQR_rough = Q3_rough - Q1_rough\n",
    "total_con['Rougher'] = np.clip(total_con['Rougher'], Q1_rough - 1.5 * IQR_rough, Q3_rough + 1.5 * IQR_rough)\n",
    "</pre>\n",
    "\n",
    "<p>&nbsp;&nbsp;&nbsp;&nbsp;The same approach was applied to the primary cleaner concentrations to detect potential anomalies.</p>\n",
    "\n",
    "<h4>Findings and Implications</h4>\n",
    "<p>&nbsp;&nbsp;&nbsp;&nbsp;After performing anomaly detection, we found that the total concentration values for certain stages had anomalies that could impact the accuracy of predictions. These anomalies were either due to data errors, unexpected processing behavior, or rare occurrences in the purification process. Handling these anomalies is crucial to maintain the integrity of the data and the model’s predictive performance.</p>\n",
    "\n",
    "<p>&nbsp;&nbsp;&nbsp;&nbsp;Mitigation strategies include removing or correcting the anomalous values, depending on their cause, and retraining the model to ensure it is based on reliable and consistent data.</p>\n",
    "\n",
    "<h4>Summary of Total Concentration Analysis</h4>\n",
    "<p>&nbsp;&nbsp;&nbsp;&nbsp;The total concentration analysis provided valuable insights into the data quality across various purification stages. By applying anomaly detection methods such as IQR, we were able to identify and address potential issues in the data. This comprehensive analysis ensures that the data used to train the model is of high quality, which directly contributes to the accuracy and reliability of the final predictions.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Preprocessing Conclusions and Observations</h3>\n",
    "<p>&nbsp;&nbsp;&nbsp;&nbsp;The data was first loaded and examined to identify key features and common characteristics across the three datasets. It was quickly evident that the test set contained the most missing columns, which were critical for understanding the purification process, especially in terms of concentrate and tail data, recovery metrics, and key ratios. These missing features were especially important for predicting recovery efficiency, and therefore, were handled with great care. I chose <i>mean imputation</i> for numerical features, based on the assumption that the missing values were missing at random and that the mean would provide a reasonable approximation. This method was applied consistently across the <b>training</b>, <b>test</b>, and <b>full</b> datasets.</p>\n",
    "<p>&nbsp;&nbsp;&nbsp;&nbsp;To prevent <b><i>data leakage</i></b> (using future information to predict past data), the imputer was <b>fit only on the training dataset</b>. This ensures that the test and full datasets were not used in any way during the training phase. As a result, all datasets now contain the same set of features, ensuring consistency during both training and evaluation. After cleaning the dataset, I proceeded with the calculations for gold recovery features.</p>\n",
    "<p>&nbsp;&nbsp;&nbsp;&nbsp;One of the more critical preprocessing tasks was ensuring the <b>total concentrations</b> of key metals across <b>all</b> purification stages (rougher, primary cleaner, final output) were reasonable. These were calculated to capture the effectiveness of the different stages in recovering valuable metals like gold, silver, and lead. After <b>summing</b> the relevant concentrations, I applied anomaly detection using the <b>IQR (Interquartile Range)</b> method to identify and manage outliers. The anomalies found during this step were either <b>corrected or removed</b> to ensure the data quality remained high.</p>\n",
    "<p>&nbsp;&nbsp;&nbsp;&nbsp;The final aspect of preprocessing was addressing the <b>extreme outliers</b> within the calculated recovery data. By imposing a cap based on the <b>25th</b> and <b>75th</b> quantiles to ensure values fell within a reasonable range, I was able to produce a <b>nominal Mean Absolute Error</b> of just over <b>4%</b> between the cleaned <b>calculated recovery</b> and the cleaned <b>rough recovery</b> values. This validated the preprocessing steps and ensured that they won't adversely affect model performance.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Primary Analysis</h2>\n",
    "<h3>Extracting and Modeling Data</h3>\n",
    "<ol>\n",
    "    <li>Dividing and Pulling Data into different categories (Metal and Stages)</li>\n",
    "    <li>Plotting pulled Data Along Box Plot to visualize stages and metal variance</li>\n",
    "    <li>Plotting Histogram to visualize particle size between test and training sets on input feed size.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "stages = ['raw_feed', 'rougher', 'final']\n",
    "metals = ['au', 'ag', 'pb']\n",
    "\n",
    "stage_data = []\n",
    "\n",
    "for metal in metals:\n",
    "    for stage in stages:\n",
    "        if stage == 'raw_feed':\n",
    "            columns = [f'rougher.input.feed_{metal}']\n",
    "            \n",
    "        elif stage == 'rougher':\n",
    "            columns = [f'rougher.output.concentrate_{metal}']\n",
    "            \n",
    "        elif stage == 'final':\n",
    "            columns = [f'final.output.concentrate_{metal}']\n",
    "        \n",
    "        concentration_values = full_df[col].values \n",
    "\n",
    "        for concentration in concentration_values:\n",
    "            stage_data.append({\n",
    "                'stage': stage,\n",
    "                'metal': metal,\n",
    "                'concentration': concentration\n",
    "            })\n",
    "            \n",
    "stage_df = pd.DataFrame(stage_data)\n",
    "display(stage_df.head())\n",
    "stage_df['stage'] = stage_df['stage'].astype('category')\n",
    "stage_df['metal'] = stage_df['metal'].astype('category')\n",
    "stage_df['concentration'] = pd.to_numeric(stage_df['concentration'], errors='coerce')\n",
    "stage_df = stage_df.dropna(subset=['concentration'])\n",
    "print(stage_df.head())\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "sns.boxplot(x='stage', y='concentration', hue='metal', data=stage_df)\n",
    "plt.title('Metal Concentrations Across Stages')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot feed particle size distribution for training and test sets\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.kdeplot(train_df['primary_cleaner.input.feed_size'], label=\"Train Set\", shade=True)\n",
    "sns.kdeplot(test_df['primary_cleaner.input.feed_size'], label=\"Test Set\", shade=True)\n",
    "plt.title('Feed Particle Size Distribution in Training vs Test Set')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Conclusions and Key insights</h3>\n",
    "<p>&nbsp;&nbsp;&nbsp;&nbsp;Through analysis of metal concentrations across stages, we observed <b>consistent</b> distribution patterns, indicating <b>stable</b> processes. The comparison of feed particle sizes between training and test sets reveals <b>minimal variance</b>, supporting a robust model evaluation. No significant anomalies were identified in total concentration distributions, confirming dataset reliability. These findings suggest the current processes maintain uniform quality and the datasets are <b>suitable</b> for predictive modeling efforts.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Model Construction and Testing</h2>\n",
    "<h3>Model Construction</h3>\n",
    "<p>The goal of this section is to enhance gold recovery prediction accuracy through the construction and testing of three distinct models. First, I will use a Linear Regression model as a baseline to capture the key structure and uniformity observed in the previous analysis. Next, I will construct a Random Forest Regressor model to capture the more nuanced variability in the data that may not be apparent from the initial analysis. Finally, I will employ Ridge and Lasso Regression models to introduce regularization and improve generalization over the Linear Regression model.</p>\n",
    "<p>Each model will be evaluated using cross-validation and the sMAPE metric to ensure a robust and consistent analysis.</p>\n",
    "<ol>\n",
    "    <li>Linear Regression Model\n",
    "        <ol>\n",
    "            <li>Hyperparameter Tuning</li>\n",
    "            <li>Cross Validation</li>\n",
    "            <li>Calculating sMAPE</li>\n",
    "        </ol>\n",
    "    </li>\n",
    "    <li>Random Forest Regressor Model\n",
    "        <ol>\n",
    "            <li>Hyperparameter Tuning</li>\n",
    "            <li>Cross Validation</li>\n",
    "            <li>Calculating sMAPE</li>\n",
    "        </ol>\n",
    "    </li>\n",
    "    <li>Ridge and Lasso Regression Models\n",
    "        <ol>\n",
    "            <li>Hyperparameter Tuning</li>\n",
    "            <li>Cross Validation</li>\n",
    "            <li>Calculating sMAPE</li>\n",
    "        </ol>\n",
    "    </li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    'rougher.input.feed_au', 'rougher.input.feed_ag', 'rougher.input.feed_pb', 'rougher.input.feed_sol', \n",
    "    'rougher.input.feed_size', 'rougher.input.floatbank10_sulfate', 'rougher.input.floatbank10_xanthate',\n",
    "    'rougher.input.floatbank11_sulfate', 'rougher.input.floatbank11_xanthate', \n",
    "    'rougher.state.floatbank10_a_air', 'rougher.state.floatbank10_a_level', 'rougher.state.floatbank10_b_air', \n",
    "    'rougher.state.floatbank10_b_level', 'rougher.state.floatbank10_c_air', 'rougher.state.floatbank10_c_level', \n",
    "    'rougher.state.floatbank10_d_air', 'rougher.state.floatbank10_d_level'\n",
    "]\n",
    "\n",
    "target = 'rougher.output.recovery'\n",
    "\n",
    "X = train_df[features]\n",
    "y = train_df[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X, y)\n",
    "\n",
    "# Custom cross-validation with sMAPE\n",
    "y_pred = cross_val_predict(lr_model, X, y, cv=5)\n",
    "smape_value = smape(y, y_pred)\n",
    "\n",
    "print(f\"Linear Regression sMAPE: {smape_value:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Linear Regression Model Conclusions</h4>\n",
    "<p>&nbsp;&nbsp;&nbsp;&nbsp;As a baseline having a sMAPE of 11.28% isn't bad. This suggests what I observed in the preliminary analysis, that with the data being uniform and each process showing strong correlation to the overall recovery these models should produce effective and reliable results.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Hyperparameter Tuning</h3>\n",
    "<p>For each of the more complicated models, I will perform hyperparameter tuning to find the optimal set of parameters that maximizes model performance. The following hyperparameters will be tuned:</p>\n",
    "<ul>\n",
    "    <li><strong>Random Forest Regressor Model</strong>: The hyperparameters to be tuned include:\n",
    "        <ul>\n",
    "            <li><strong>n_estimators</strong>: The number of trees in the forest. I will explore values such as 10,\n",
    "                25, and 50 to understand the trade-off between model complexity and computation time.</li>\n",
    "            <li><strong>max_depth</strong>: The maximum depth of each tree. A deeper tree may capture more\n",
    "                information but could risk overfitting. I will explore a range from None to 30 in increments of 10\n",
    "            </li>\n",
    "            <li><strong>min_samples_split</strong>: The minimum number of samples required to split an internal\n",
    "                node. A higher value can help prevent overfitting by making the tree more conservative in\n",
    "                splitting.</li>\n",
    "            <li><strong>min_samples_leaf</strong>: The minimum number of samples required to be at a leaf node. A\n",
    "                higher value can help smooth the model and reduce overfitting.</li>\n",
    "            <li><strong>max_features</strong>: The number of features to consider when looking for the best split.\n",
    "                This helps to reduce the model’s variance by making trees more diverse. Common values include\n",
    "                'auto', 'sqrt', 'log2', or an integer number of features.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li><strong>Ridge and Lasso Regression Models</strong>: I will primarily focus on tuning the 'alpha' parameter.</li>\n",
    "</ul>\n",
    "<p>I will use <strong>GridSearchCV</strong> for exhaustive searching over the parameter space. For computational efficiency, I may also use <strong>RandomizedSearchCV</strong> if the grid search becomes too time-consuming. Cross-validation will be applied to ensure the model is validated on different subsets of the data, and I will evaluate performance using the sMAPE metric.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "rf_para_grid = {\n",
    "    'n_estimators': [10, 25, 50, 100],\n",
    "    'max_depth': [None, 10, 20, 30, 40],\n",
    "    'min_samples_split': [2, 5, 10, 15],\n",
    "    'min_samples_leaf': [1, 2, 4, 6],\n",
    "    'max_features': ['auto', 'sqrt', 'log2', None]\n",
    "}\n",
    "\n",
    "rf_search = RandomizedSearchCV(\n",
    "    rf_model, param_distributions=rf_para_grid, n_iter=10, cv=None,\n",
    "    n_jobs=-1, scoring=smape_scorer, random_state=42)\n",
    "rf_search.fit(X, y)\n",
    "\n",
    "y_pred_rf = cross_val_predict(rf_search.best_estimator_, X, y, cv=5)\n",
    "smape_rf = smape(y, y_pred_rf)\n",
    "\n",
    "print(f\"Random Forest sMAPE: {smape_rf:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Feature Importance for Random Forest Regressor Model</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importances from the best model\n",
    "importances = rf_search.best_estimator_.feature_importances_\n",
    "\n",
    "# Visualize feature importances\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(X.columns, importances)\n",
    "plt.xlabel(\"Feature Importance\")\n",
    "plt.title(\"Feature Importance in Random Forest Model\")\n",
    "plt.show()\n",
    "\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"Feature\"] = X.columns\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "\n",
    "display(vif_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Random Forest Model Conclusions**\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;After analysis of the better preforming model, the analysis revealed that `rougher.input.feed_au` and `rougher.input.floatbank10_sulfate` are the most impactful features in predicting gold recovery. This aligns with expectations, as gold concentration and flotation chemicals directly affect recovery efficiency.</br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;Features such as `rougher.state.floatbank10_c_air` were found to have minimal impact, suggesting potential redundancy. Further evaluation could determine if these variables may be safely excluded to streamline a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RidgeCV\n",
    "ridge_para_grid = {\n",
    "    'alpha': np.logspace(-3, 3, 7)\n",
    "}\n",
    "\n",
    "ridge_grid = GridSearchCV(Ridge(), ridge_para_grid, scoring=smape_scorer, n_jobs=-1, cv=None)\n",
    "ridge_grid.fit(X, y)\n",
    "\n",
    "y_pred_ridge = cross_val_predict(ridge_grid, X, y, cv=5)\n",
    "smape_ridge = smape(y, y_pred_ridge)\n",
    "\n",
    "print(f\"Ridge Regression sMAPE: {smape_ridge:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>RidgeCV Model Conclusion</h4>\n",
    "<p>&nbsp;&nbsp;&nbsp;&nbsp;The Ridge Model, with hypertuned alpha parameters, preformed marginally better than the baseline Linear Regression Model. Implying it was unable to discern any deeper meaningful connection outside of the heavy correlation already present within the data. Unable to discribe the nuance that the Random Forest Model was able to pickup on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LassoCV\n",
    "lasso_para_grid = {\n",
    "    'alpha': np.logspace(-3, 3, 7)\n",
    "}\n",
    "\n",
    "lasso_grid = GridSearchCV(Lasso(), lasso_para_grid, scoring=smape_scorer, n_jobs=-1, cv=None)\n",
    "lasso_grid.fit(X, y)\n",
    "\n",
    "y_pred_lasso = cross_val_predict(lasso_grid, X, y, cv=5)\n",
    "smape_lasso = smape(y, y_pred_lasso)\n",
    "\n",
    "print(f\"Lasso Cross Validation sMAPE: {smape_lasso:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>LassoCV Model Conclusion</h4>\n",
    "<p>&nbsp;&nbsp;&nbsp;&nbsp;The LassoCV Model preformed the best between all of the provided models. The Lasso CV was clearly able to interpret deeper connections between features than the more extensive and rigid Random Forest Model. This implies that several of the features present in the model are realitive \"noise\" when it comes to correctly identifying the recovery of gold. Lasso being able to distinguish what is, and isn't, important is a key metric and benefit to producing the results we are interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the superiour LassoCV Model on the Test Set\n",
    "X_test = test_df[features]\n",
    "y_test = test_df[target]\n",
    "\n",
    "y_pred_test = lasso_grid.predict(X_test)\n",
    "\n",
    "smape_test = smape(y_test, y_pred_test)\n",
    "\n",
    "print(f\"Lasso Model Test Set sMAPE: {smape_test:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Conclusions</h2>\n",
    "\n",
    "<h3>Model Conclusion</h3>\n",
    "<p>&nbsp;&nbsp;&nbsp;&nbsp;As you can clearly see from the sMAPE of the cross validated models, the Lasso Cross Validation Model was able to find a meaningful similarity within the features to properly identify characteristics for gold processing in order to more accurately predict gold recovery. The thorough evaluation process using cross-validation and sMAPE provided robust insights into model performance. This comprehensive approach ensured that the selected model is well-suited for predicting gold recovery with accuracy and reliability. Evidenced by its excellent sMAPE score against the untouched testing set.</p>\n",
    "\n",
    "<h3>Project Conclusion and Insights</h3>\n",
    "<p>&nbsp;&nbsp;&nbsp;&nbsp;This project aimed to develop a machine learning model to optimize gold recovery processes for Zyfra. By thoroughly preparing and analyzing the data, we ensured high data quality and consistency across training and testing phases. Through careful model construction and evaluation, we identified a model that proficiently predicts gold recovery, helping to optimize production and eliminate unprofitable parameters. This effort paves the way for improved operational efficiency, aligning with Zyfra's goals for innovation in heavy industry.</p>"
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 801,
    "start_time": "2024-11-27T23:07:47.686Z"
   },
   {
    "duration": 61,
    "start_time": "2024-11-27T23:08:06.074Z"
   },
   {
    "duration": 615,
    "start_time": "2024-11-27T23:09:25.733Z"
   },
   {
    "duration": 523,
    "start_time": "2024-11-27T23:12:30.428Z"
   },
   {
    "duration": 541,
    "start_time": "2024-11-27T23:13:39.340Z"
   },
   {
    "duration": 526,
    "start_time": "2024-11-27T23:14:13.055Z"
   },
   {
    "duration": 532,
    "start_time": "2024-11-27T23:14:46.410Z"
   },
   {
    "duration": 11,
    "start_time": "2024-11-27T23:25:50.672Z"
   },
   {
    "duration": 14,
    "start_time": "2024-11-27T23:26:11.645Z"
   },
   {
    "duration": 957,
    "start_time": "2024-11-27T23:26:25.346Z"
   },
   {
    "duration": 197,
    "start_time": "2024-11-27T23:26:28.837Z"
   },
   {
    "duration": 3,
    "start_time": "2024-11-27T23:27:58.705Z"
   },
   {
    "duration": 4,
    "start_time": "2024-11-27T23:30:33.690Z"
   },
   {
    "duration": 15,
    "start_time": "2024-11-27T23:30:49.960Z"
   },
   {
    "duration": 446,
    "start_time": "2024-11-27T23:31:09.621Z"
   },
   {
    "duration": 6,
    "start_time": "2024-11-27T23:31:12.793Z"
   },
   {
    "duration": 471,
    "start_time": "2024-11-27T23:34:56.124Z"
   },
   {
    "duration": 510,
    "start_time": "2024-11-27T23:37:19.029Z"
   },
   {
    "duration": 5,
    "start_time": "2024-11-27T23:37:22.001Z"
   },
   {
    "duration": 3,
    "start_time": "2024-11-27T23:37:22.630Z"
   },
   {
    "duration": 85,
    "start_time": "2024-11-27T23:37:23.568Z"
   },
   {
    "duration": 91,
    "start_time": "2024-11-27T23:39:14.271Z"
   },
   {
    "duration": 130,
    "start_time": "2024-11-27T23:41:08.552Z"
   },
   {
    "duration": 76,
    "start_time": "2024-11-27T23:41:45.271Z"
   },
   {
    "duration": 80,
    "start_time": "2024-11-27T23:44:25.295Z"
   },
   {
    "duration": 7,
    "start_time": "2024-11-27T23:46:11.850Z"
   },
   {
    "duration": 533,
    "start_time": "2024-11-27T23:55:19.916Z"
   },
   {
    "duration": 156,
    "start_time": "2024-11-27T23:56:33.302Z"
   },
   {
    "duration": 145,
    "start_time": "2024-11-27T23:57:11.748Z"
   },
   {
    "duration": 316,
    "start_time": "2024-11-27T23:57:15.125Z"
   },
   {
    "duration": 6,
    "start_time": "2024-11-27T23:57:24.752Z"
   },
   {
    "duration": 256,
    "start_time": "2024-11-27T23:58:24.609Z"
   },
   {
    "duration": 457,
    "start_time": "2024-11-28T00:03:02.777Z"
   },
   {
    "duration": 5,
    "start_time": "2024-11-28T00:03:05.659Z"
   },
   {
    "duration": 4,
    "start_time": "2024-11-28T00:03:06.154Z"
   },
   {
    "duration": 105,
    "start_time": "2024-11-28T00:03:07.165Z"
   },
   {
    "duration": 75,
    "start_time": "2024-11-28T00:03:09.317Z"
   },
   {
    "duration": 5,
    "start_time": "2024-11-28T00:03:20.818Z"
   },
   {
    "duration": 76,
    "start_time": "2024-11-28T00:04:24.277Z"
   },
   {
    "duration": 79,
    "start_time": "2024-11-28T00:05:30.646Z"
   },
   {
    "duration": 146,
    "start_time": "2024-11-28T00:06:15.965Z"
   },
   {
    "duration": 149,
    "start_time": "2024-11-28T00:06:33.132Z"
   },
   {
    "duration": 6,
    "start_time": "2024-11-28T00:08:38.556Z"
   },
   {
    "duration": 9,
    "start_time": "2024-11-28T00:08:53.419Z"
   },
   {
    "duration": 80,
    "start_time": "2024-11-28T00:09:44.824Z"
   },
   {
    "duration": 76,
    "start_time": "2024-11-28T00:10:56.366Z"
   },
   {
    "duration": 6,
    "start_time": "2024-11-28T00:12:38.358Z"
   },
   {
    "duration": 7,
    "start_time": "2024-11-28T00:12:49.565Z"
   },
   {
    "duration": 7,
    "start_time": "2024-11-28T00:13:04.438Z"
   },
   {
    "duration": 6,
    "start_time": "2024-11-28T00:13:20.758Z"
   },
   {
    "duration": 13,
    "start_time": "2024-11-28T00:13:33.866Z"
   },
   {
    "duration": 141,
    "start_time": "2024-11-28T00:14:23.869Z"
   },
   {
    "duration": 152,
    "start_time": "2024-11-28T00:14:46.230Z"
   },
   {
    "duration": 464,
    "start_time": "2024-11-28T00:19:59.510Z"
   },
   {
    "duration": 147,
    "start_time": "2024-11-28T00:20:01.900Z"
   },
   {
    "duration": 175,
    "start_time": "2024-11-28T00:26:30.418Z"
   },
   {
    "duration": 181,
    "start_time": "2024-11-28T00:26:47.673Z"
   },
   {
    "duration": 296,
    "start_time": "2024-11-28T00:28:03.352Z"
   },
   {
    "duration": 627,
    "start_time": "2024-11-28T00:34:53.131Z"
   },
   {
    "duration": 318,
    "start_time": "2024-11-28T00:37:57.609Z"
   },
   {
    "duration": 535,
    "start_time": "2024-11-28T00:38:51.336Z"
   },
   {
    "duration": 519,
    "start_time": "2024-11-28T00:44:56.778Z"
   },
   {
    "duration": 508,
    "start_time": "2024-11-28T00:45:10.144Z"
   },
   {
    "duration": 175,
    "start_time": "2024-11-28T00:45:12.416Z"
   },
   {
    "duration": 606,
    "start_time": "2024-11-28T00:45:32.634Z"
   },
   {
    "duration": 138,
    "start_time": "2024-11-28T01:03:39.869Z"
   },
   {
    "duration": 497,
    "start_time": "2024-11-28T01:03:52.886Z"
   },
   {
    "duration": 159,
    "start_time": "2024-11-28T01:03:55.484Z"
   },
   {
    "duration": 562,
    "start_time": "2024-11-28T01:04:03.981Z"
   },
   {
    "duration": 845,
    "start_time": "2024-11-28T01:04:41.356Z"
   },
   {
    "duration": 510,
    "start_time": "2024-11-28T01:05:06.737Z"
   },
   {
    "duration": 424,
    "start_time": "2024-11-28T01:05:28.358Z"
   },
   {
    "duration": 2589,
    "start_time": "2024-11-28T01:27:25.182Z"
   },
   {
    "duration": 34,
    "start_time": "2024-11-28T01:31:55.740Z"
   },
   {
    "duration": 168,
    "start_time": "2024-11-28T01:34:42.236Z"
   },
   {
    "duration": 47,
    "start_time": "2024-11-28T01:35:12.498Z"
   },
   {
    "duration": 212,
    "start_time": "2024-11-28T01:35:35.916Z"
   },
   {
    "duration": 105,
    "start_time": "2024-11-28T01:40:35.335Z"
   },
   {
    "duration": 3,
    "start_time": "2024-11-28T01:42:43.121Z"
   },
   {
    "duration": 161,
    "start_time": "2024-11-28T01:43:52.693Z"
   },
   {
    "duration": 135,
    "start_time": "2024-11-28T01:44:08.814Z"
   },
   {
    "duration": 13,
    "start_time": "2024-11-28T01:48:16.132Z"
   },
   {
    "duration": 14,
    "start_time": "2024-11-28T01:48:26.841Z"
   },
   {
    "duration": 14,
    "start_time": "2024-11-28T01:48:41.006Z"
   },
   {
    "duration": 6,
    "start_time": "2024-11-28T01:48:48.493Z"
   },
   {
    "duration": 3,
    "start_time": "2024-11-28T01:48:56.196Z"
   },
   {
    "duration": 55,
    "start_time": "2024-11-28T01:49:51.949Z"
   },
   {
    "duration": 4,
    "start_time": "2024-11-28T01:52:02.920Z"
   },
   {
    "duration": 62,
    "start_time": "2024-11-28T01:54:36.962Z"
   },
   {
    "duration": 82,
    "start_time": "2024-11-28T01:56:17.466Z"
   },
   {
    "duration": 143,
    "start_time": "2024-11-28T01:57:16.205Z"
   },
   {
    "duration": 139,
    "start_time": "2024-11-28T01:58:10.174Z"
   },
   {
    "duration": 139,
    "start_time": "2024-11-28T01:58:57.207Z"
   },
   {
    "duration": 147,
    "start_time": "2024-11-28T02:00:10.023Z"
   },
   {
    "duration": 22,
    "start_time": "2024-11-28T02:00:20.907Z"
   },
   {
    "duration": 139,
    "start_time": "2024-11-28T02:00:28.789Z"
   },
   {
    "duration": 141,
    "start_time": "2024-11-28T02:00:46.987Z"
   },
   {
    "duration": 356,
    "start_time": "2024-11-28T02:03:03.943Z"
   },
   {
    "duration": 567,
    "start_time": "2024-11-28T02:06:05.586Z"
   },
   {
    "duration": 511,
    "start_time": "2024-11-28T02:15:21.055Z"
   },
   {
    "duration": 197,
    "start_time": "2024-11-28T02:19:12.236Z"
   },
   {
    "duration": 462,
    "start_time": "2024-11-28T02:21:02.191Z"
   },
   {
    "duration": 145,
    "start_time": "2024-11-28T02:21:09.541Z"
   },
   {
    "duration": 405,
    "start_time": "2024-11-28T02:21:22.563Z"
   },
   {
    "duration": 56,
    "start_time": "2024-11-28T02:21:25.825Z"
   },
   {
    "duration": 518,
    "start_time": "2024-11-28T02:21:36.446Z"
   },
   {
    "duration": 156,
    "start_time": "2024-11-28T02:21:37.882Z"
   },
   {
    "duration": 419,
    "start_time": "2024-11-28T02:21:40.870Z"
   },
   {
    "duration": 52,
    "start_time": "2024-11-28T02:21:43.447Z"
   },
   {
    "duration": 70,
    "start_time": "2024-11-28T02:23:14.763Z"
   },
   {
    "duration": 134,
    "start_time": "2024-11-28T02:24:09.411Z"
   },
   {
    "duration": 68,
    "start_time": "2024-11-28T02:24:29.969Z"
   },
   {
    "duration": 68,
    "start_time": "2024-11-28T02:24:55.865Z"
   },
   {
    "duration": 516,
    "start_time": "2024-11-28T02:26:15.330Z"
   },
   {
    "duration": 143,
    "start_time": "2024-11-28T02:26:19.537Z"
   },
   {
    "duration": 404,
    "start_time": "2024-11-28T02:26:30.808Z"
   },
   {
    "duration": 56,
    "start_time": "2024-11-28T02:28:10.322Z"
   },
   {
    "duration": 4,
    "start_time": "2024-11-28T02:29:02.685Z"
   },
   {
    "duration": 71,
    "start_time": "2024-11-28T02:29:12.644Z"
   },
   {
    "duration": 509,
    "start_time": "2024-11-28T02:29:27.133Z"
   },
   {
    "duration": 140,
    "start_time": "2024-11-28T02:29:32.948Z"
   },
   {
    "duration": 432,
    "start_time": "2024-11-28T02:29:39.003Z"
   },
   {
    "duration": 382,
    "start_time": "2024-11-28T02:29:58.346Z"
   },
   {
    "duration": 376,
    "start_time": "2024-11-28T02:30:14.394Z"
   },
   {
    "duration": 382,
    "start_time": "2024-11-28T02:30:55.812Z"
   },
   {
    "duration": 372,
    "start_time": "2024-11-28T02:31:24.657Z"
   },
   {
    "duration": 514,
    "start_time": "2024-11-28T02:31:31.500Z"
   },
   {
    "duration": 142,
    "start_time": "2024-11-28T02:31:35.087Z"
   },
   {
    "duration": 393,
    "start_time": "2024-11-28T02:31:38.358Z"
   },
   {
    "duration": 507,
    "start_time": "2024-11-28T02:32:21.609Z"
   },
   {
    "duration": 426,
    "start_time": "2024-11-28T02:32:40.376Z"
   },
   {
    "duration": 382,
    "start_time": "2024-11-28T02:32:50.721Z"
   },
   {
    "duration": 399,
    "start_time": "2024-11-28T02:33:38.327Z"
   },
   {
    "duration": 54,
    "start_time": "2024-11-28T02:33:41.329Z"
   },
   {
    "duration": 71,
    "start_time": "2024-11-28T02:35:16.085Z"
   },
   {
    "duration": 529,
    "start_time": "2024-11-28T02:35:29.127Z"
   },
   {
    "duration": 140,
    "start_time": "2024-11-28T02:35:31.750Z"
   },
   {
    "duration": 406,
    "start_time": "2024-11-28T02:35:34.172Z"
   },
   {
    "duration": 429,
    "start_time": "2024-11-28T02:37:35.963Z"
   },
   {
    "duration": 386,
    "start_time": "2024-11-28T02:37:56.578Z"
   },
   {
    "duration": 386,
    "start_time": "2024-11-28T02:38:24.868Z"
   },
   {
    "duration": 394,
    "start_time": "2024-11-28T02:38:40.892Z"
   },
   {
    "duration": 6,
    "start_time": "2024-11-28T02:42:27.763Z"
   },
   {
    "duration": 143,
    "start_time": "2024-11-28T14:14:13.034Z"
   },
   {
    "duration": 533,
    "start_time": "2024-11-28T14:14:19.902Z"
   },
   {
    "duration": 210,
    "start_time": "2024-11-28T14:14:25.017Z"
   },
   {
    "duration": 148,
    "start_time": "2024-11-28T14:17:06.939Z"
   },
   {
    "duration": 148,
    "start_time": "2024-11-28T14:18:04.001Z"
   },
   {
    "duration": 165,
    "start_time": "2024-11-28T14:18:51.800Z"
   },
   {
    "duration": 146,
    "start_time": "2024-11-28T14:19:04.376Z"
   },
   {
    "duration": 4,
    "start_time": "2024-11-28T14:19:33.199Z"
   },
   {
    "duration": 147,
    "start_time": "2024-11-28T14:19:42.407Z"
   },
   {
    "duration": 145,
    "start_time": "2024-11-28T14:19:56.398Z"
   },
   {
    "duration": 259,
    "start_time": "2024-11-28T14:21:23.223Z"
   },
   {
    "duration": 521,
    "start_time": "2024-11-28T14:21:39.661Z"
   },
   {
    "duration": 145,
    "start_time": "2024-11-28T14:21:40.632Z"
   },
   {
    "duration": 406,
    "start_time": "2024-11-28T14:21:41.954Z"
   },
   {
    "duration": 6,
    "start_time": "2024-11-28T14:21:43.879Z"
   },
   {
    "duration": 241,
    "start_time": "2024-11-28T14:22:06.574Z"
   },
   {
    "duration": 516,
    "start_time": "2024-11-28T14:22:13.597Z"
   },
   {
    "duration": 145,
    "start_time": "2024-11-28T14:22:14.507Z"
   },
   {
    "duration": 423,
    "start_time": "2024-11-28T14:22:15.501Z"
   },
   {
    "duration": 6,
    "start_time": "2024-11-28T14:22:16.454Z"
   },
   {
    "duration": 241,
    "start_time": "2024-11-28T14:23:34.387Z"
   },
   {
    "duration": 523,
    "start_time": "2024-11-28T14:23:46.363Z"
   },
   {
    "duration": 156,
    "start_time": "2024-11-28T14:23:47.411Z"
   },
   {
    "duration": 417,
    "start_time": "2024-11-28T14:23:48.597Z"
   },
   {
    "duration": 393,
    "start_time": "2024-11-28T14:27:41.268Z"
   },
   {
    "duration": 553,
    "start_time": "2024-11-28T14:27:57.470Z"
   },
   {
    "duration": 149,
    "start_time": "2024-11-28T14:27:58.476Z"
   },
   {
    "duration": 410,
    "start_time": "2024-11-28T14:28:01.579Z"
   },
   {
    "duration": 483,
    "start_time": "2024-11-28T14:29:11.876Z"
   },
   {
    "duration": 144,
    "start_time": "2024-11-28T14:29:12.635Z"
   },
   {
    "duration": 408,
    "start_time": "2024-11-28T14:29:13.865Z"
   },
   {
    "duration": 135,
    "start_time": "2024-11-28T14:31:17.107Z"
   },
   {
    "duration": 459,
    "start_time": "2024-11-28T14:50:31.333Z"
   },
   {
    "duration": 410,
    "start_time": "2024-11-28T14:50:34.802Z"
   },
   {
    "duration": 61,
    "start_time": "2024-11-28T14:50:40.621Z"
   },
   {
    "duration": 54,
    "start_time": "2024-11-28T14:50:50.720Z"
   },
   {
    "duration": 4,
    "start_time": "2024-11-28T14:51:46.411Z"
   },
   {
    "duration": 53,
    "start_time": "2024-11-28T14:53:51.818Z"
   },
   {
    "duration": 4,
    "start_time": "2024-11-28T14:53:56.594Z"
   },
   {
    "duration": 144,
    "start_time": "2024-11-28T14:55:28.384Z"
   },
   {
    "duration": 10,
    "start_time": "2024-11-28T14:56:04.488Z"
   },
   {
    "duration": 9,
    "start_time": "2024-11-28T14:59:40.683Z"
   },
   {
    "duration": 5,
    "start_time": "2024-11-28T14:59:49.180Z"
   },
   {
    "duration": 8,
    "start_time": "2024-11-28T15:09:05.852Z"
   },
   {
    "duration": 3,
    "start_time": "2024-11-28T15:14:02.298Z"
   },
   {
    "duration": 459,
    "start_time": "2024-11-28T15:14:03.452Z"
   },
   {
    "duration": 527,
    "start_time": "2024-11-28T15:14:13.348Z"
   },
   {
    "duration": 2,
    "start_time": "2024-11-28T15:41:25.771Z"
   },
   {
    "duration": 3,
    "start_time": "2024-11-28T15:41:26.386Z"
   },
   {
    "duration": 11,
    "start_time": "2024-11-28T16:03:07.149Z"
   },
   {
    "duration": 3,
    "start_time": "2024-11-28T16:03:07.555Z"
   },
   {
    "duration": 531,
    "start_time": "2024-11-28T16:03:08.593Z"
   },
   {
    "duration": 145,
    "start_time": "2024-11-28T16:03:09.133Z"
   },
   {
    "duration": 412,
    "start_time": "2024-11-28T16:03:10.387Z"
   },
   {
    "duration": 10,
    "start_time": "2024-11-28T16:03:11.371Z"
   },
   {
    "duration": 7,
    "start_time": "2024-11-28T16:03:12.200Z"
   },
   {
    "duration": 653,
    "start_time": "2024-11-28T16:03:14.218Z"
   },
   {
    "duration": 496,
    "start_time": "2024-11-28T16:03:14.971Z"
   },
   {
    "duration": 30,
    "start_time": "2024-11-28T16:31:49.402Z"
   },
   {
    "duration": 4,
    "start_time": "2024-11-28T16:33:32.378Z"
   },
   {
    "duration": 305,
    "start_time": "2024-11-28T16:33:36.719Z"
   },
   {
    "duration": 980,
    "start_time": "2024-11-28T16:39:09.272Z"
   },
   {
    "duration": 3,
    "start_time": "2024-11-28T16:39:10.254Z"
   },
   {
    "duration": 550,
    "start_time": "2024-11-28T16:39:10.259Z"
   },
   {
    "duration": 151,
    "start_time": "2024-11-28T16:39:10.824Z"
   },
   {
    "duration": 444,
    "start_time": "2024-11-28T16:39:10.977Z"
   },
   {
    "duration": 9,
    "start_time": "2024-11-28T16:39:11.424Z"
   },
   {
    "duration": 7,
    "start_time": "2024-11-28T16:39:11.435Z"
   },
   {
    "duration": 487,
    "start_time": "2024-11-28T16:39:11.444Z"
   },
   {
    "duration": 550,
    "start_time": "2024-11-28T16:39:11.932Z"
   },
   {
    "duration": 337,
    "start_time": "2024-11-28T16:39:12.486Z"
   },
   {
    "duration": 112943,
    "start_time": "2024-11-28T16:39:12.825Z"
   },
   {
    "duration": 1863,
    "start_time": "2024-11-28T16:41:05.770Z"
   },
   {
    "duration": 33947,
    "start_time": "2024-11-28T16:42:13.163Z"
   },
   {
    "duration": 4,
    "start_time": "2024-11-28T16:43:50.642Z"
   },
   {
    "duration": 16966,
    "start_time": "2024-11-28T16:47:14.522Z"
   },
   {
    "duration": 27219,
    "start_time": "2024-11-28T16:47:43.705Z"
   },
   {
    "duration": 2696,
    "start_time": "2024-12-02T14:30:52.517Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-02T14:30:55.216Z"
   },
   {
    "duration": 638,
    "start_time": "2024-12-02T14:30:55.221Z"
   },
   {
    "duration": 165,
    "start_time": "2024-12-02T14:30:55.862Z"
   },
   {
    "duration": 449,
    "start_time": "2024-12-02T14:30:56.028Z"
   },
   {
    "duration": 11,
    "start_time": "2024-12-02T14:30:56.479Z"
   },
   {
    "duration": 7,
    "start_time": "2024-12-02T14:30:56.491Z"
   },
   {
    "duration": 491,
    "start_time": "2024-12-02T14:30:56.499Z"
   },
   {
    "duration": 595,
    "start_time": "2024-12-02T14:30:56.992Z"
   },
   {
    "duration": 8,
    "start_time": "2024-12-02T14:30:57.589Z"
   },
   {
    "duration": 246,
    "start_time": "2024-12-02T14:30:57.599Z"
   },
   {
    "duration": 27317,
    "start_time": "2024-12-02T14:30:57.847Z"
   },
   {
    "duration": 1980,
    "start_time": "2024-12-02T14:31:25.166Z"
   },
   {
    "duration": 6,
    "start_time": "2024-12-02T14:31:27.148Z"
   },
   {
    "duration": 3321,
    "start_time": "2024-12-02T14:31:42.829Z"
   },
   {
    "duration": 263,
    "start_time": "2024-12-02T15:00:54.236Z"
   },
   {
    "duration": 553,
    "start_time": "2024-12-02T15:01:14.537Z"
   },
   {
    "duration": 969,
    "start_time": "2024-12-02T15:03:15.815Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-02T15:03:16.787Z"
   },
   {
    "duration": 551,
    "start_time": "2024-12-02T15:03:16.792Z"
   },
   {
    "duration": 162,
    "start_time": "2024-12-02T15:03:17.346Z"
   },
   {
    "duration": 439,
    "start_time": "2024-12-02T15:03:17.510Z"
   },
   {
    "duration": 9,
    "start_time": "2024-12-02T15:03:17.951Z"
   },
   {
    "duration": 6,
    "start_time": "2024-12-02T15:03:17.962Z"
   },
   {
    "duration": 484,
    "start_time": "2024-12-02T15:03:17.969Z"
   },
   {
    "duration": 535,
    "start_time": "2024-12-02T15:03:18.454Z"
   },
   {
    "duration": 8,
    "start_time": "2024-12-02T15:03:18.993Z"
   },
   {
    "duration": 153,
    "start_time": "2024-12-02T15:03:19.003Z"
   },
   {
    "duration": 27339,
    "start_time": "2024-12-02T15:03:19.158Z"
   },
   {
    "duration": 1944,
    "start_time": "2024-12-02T15:03:46.498Z"
   },
   {
    "duration": 3310,
    "start_time": "2024-12-02T15:03:48.444Z"
   },
   {
    "duration": 16,
    "start_time": "2024-12-02T15:18:47.840Z"
   },
   {
    "duration": 637,
    "start_time": "2024-12-02T15:26:12.934Z"
   },
   {
    "duration": 1050,
    "start_time": "2024-12-02T15:28:09.025Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-02T15:28:10.078Z"
   },
   {
    "duration": 673,
    "start_time": "2024-12-02T15:28:10.083Z"
   },
   {
    "duration": 174,
    "start_time": "2024-12-02T15:28:10.760Z"
   },
   {
    "duration": 508,
    "start_time": "2024-12-02T15:28:10.946Z"
   },
   {
    "duration": 14,
    "start_time": "2024-12-02T15:28:11.456Z"
   },
   {
    "duration": 18,
    "start_time": "2024-12-02T15:28:11.472Z"
   },
   {
    "duration": 566,
    "start_time": "2024-12-02T15:28:11.492Z"
   },
   {
    "duration": 551,
    "start_time": "2024-12-02T15:28:12.060Z"
   },
   {
    "duration": 5,
    "start_time": "2024-12-02T15:28:12.614Z"
   },
   {
    "duration": 448,
    "start_time": "2024-12-02T15:28:12.621Z"
   },
   {
    "duration": 28464,
    "start_time": "2024-12-02T15:28:13.071Z"
   },
   {
    "duration": 1713,
    "start_time": "2024-12-02T15:28:41.537Z"
   },
   {
    "duration": 3008,
    "start_time": "2024-12-02T15:28:43.256Z"
   },
   {
    "duration": 497,
    "start_time": "2024-12-02T15:28:46.271Z"
   },
   {
    "duration": 814,
    "start_time": "2024-12-02T15:33:18.730Z"
   },
   {
    "duration": 1082,
    "start_time": "2024-12-02T15:33:44.274Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-02T15:33:45.359Z"
   },
   {
    "duration": 609,
    "start_time": "2024-12-02T15:33:45.365Z"
   },
   {
    "duration": 183,
    "start_time": "2024-12-02T15:33:45.976Z"
   },
   {
    "duration": 466,
    "start_time": "2024-12-02T15:33:46.161Z"
   },
   {
    "duration": 20,
    "start_time": "2024-12-02T15:33:46.628Z"
   },
   {
    "duration": 28,
    "start_time": "2024-12-02T15:33:46.650Z"
   },
   {
    "duration": 529,
    "start_time": "2024-12-02T15:33:46.680Z"
   },
   {
    "duration": 497,
    "start_time": "2024-12-02T15:33:47.213Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-02T15:33:47.713Z"
   },
   {
    "duration": 429,
    "start_time": "2024-12-02T15:33:47.720Z"
   },
   {
    "duration": 27801,
    "start_time": "2024-12-02T15:33:48.153Z"
   },
   {
    "duration": 3087,
    "start_time": "2024-12-02T15:34:15.956Z"
   },
   {
    "duration": 4024,
    "start_time": "2024-12-02T15:34:19.046Z"
   },
   {
    "duration": 581,
    "start_time": "2024-12-02T15:34:23.073Z"
   },
   {
    "duration": 432,
    "start_time": "2024-12-02T15:34:52.639Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-02T16:03:56.364Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-02T16:08:56.262Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-02T16:08:58.588Z"
   },
   {
    "duration": 1004,
    "start_time": "2024-12-02T16:18:39.190Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-02T16:18:40.197Z"
   },
   {
    "duration": 576,
    "start_time": "2024-12-02T16:18:40.203Z"
   },
   {
    "duration": 178,
    "start_time": "2024-12-02T16:18:40.781Z"
   },
   {
    "duration": 456,
    "start_time": "2024-12-02T16:18:40.963Z"
   },
   {
    "duration": 9,
    "start_time": "2024-12-02T16:18:41.421Z"
   },
   {
    "duration": 20,
    "start_time": "2024-12-02T16:18:41.443Z"
   },
   {
    "duration": 479,
    "start_time": "2024-12-02T16:18:41.465Z"
   },
   {
    "duration": 548,
    "start_time": "2024-12-02T16:18:41.946Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-02T16:18:42.496Z"
   },
   {
    "duration": 251,
    "start_time": "2024-12-02T16:18:42.502Z"
   },
   {
    "duration": 1015,
    "start_time": "2024-12-02T16:27:44.435Z"
   },
   {
    "duration": 1022,
    "start_time": "2024-12-02T16:28:07.576Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-02T16:28:08.601Z"
   },
   {
    "duration": 571,
    "start_time": "2024-12-02T16:28:08.606Z"
   },
   {
    "duration": 169,
    "start_time": "2024-12-02T16:28:09.179Z"
   },
   {
    "duration": 448,
    "start_time": "2024-12-02T16:28:09.350Z"
   },
   {
    "duration": 9,
    "start_time": "2024-12-02T16:28:09.800Z"
   },
   {
    "duration": 35,
    "start_time": "2024-12-02T16:28:09.811Z"
   },
   {
    "duration": 478,
    "start_time": "2024-12-02T16:28:09.848Z"
   },
   {
    "duration": 549,
    "start_time": "2024-12-02T16:28:10.328Z"
   },
   {
    "duration": 4,
    "start_time": "2024-12-02T16:28:10.881Z"
   },
   {
    "duration": 356,
    "start_time": "2024-12-02T16:28:10.887Z"
   },
   {
    "duration": 360,
    "start_time": "2024-12-02T16:28:11.245Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-02T16:28:11.608Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-02T16:28:11.609Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-02T16:28:11.611Z"
   },
   {
    "duration": 83363,
    "start_time": "2024-12-02T16:28:52.611Z"
   },
   {
    "duration": 367755,
    "start_time": "2024-12-02T16:31:15.117Z"
   },
   {
    "duration": 295,
    "start_time": "2024-12-02T16:37:27.554Z"
   },
   {
    "duration": 4475,
    "start_time": "2024-12-02T16:38:44.502Z"
   },
   {
    "duration": 4437,
    "start_time": "2024-12-02T16:40:16.253Z"
   },
   {
    "duration": 4092,
    "start_time": "2024-12-02T16:41:45.059Z"
   },
   {
    "duration": 5053,
    "start_time": "2024-12-02T16:42:08.227Z"
   },
   {
    "duration": 16,
    "start_time": "2024-12-02T16:42:54.392Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-02T16:43:09.576Z"
   },
   {
    "duration": 77,
    "start_time": "2024-12-02T16:43:16.168Z"
   },
   {
    "duration": 8824,
    "start_time": "2024-12-02T16:43:25.221Z"
   },
   {
    "duration": 78145,
    "start_time": "2024-12-02T16:43:43.718Z"
   },
   {
    "duration": 209,
    "start_time": "2024-12-02T16:45:28.058Z"
   },
   {
    "duration": 100,
    "start_time": "2024-12-02T16:46:50.477Z"
   },
   {
    "duration": 152647,
    "start_time": "2024-12-02T16:46:56.602Z"
   },
   {
    "duration": 17,
    "start_time": "2024-12-02T16:49:42.896Z"
   },
   {
    "duration": 39039,
    "start_time": "2024-12-02T16:49:57.581Z"
   },
   {
    "duration": 150939,
    "start_time": "2024-12-02T16:50:42.309Z"
   },
   {
    "duration": 18,
    "start_time": "2024-12-02T16:53:29.109Z"
   },
   {
    "duration": 156606,
    "start_time": "2024-12-02T16:53:39.458Z"
   },
   {
    "duration": 8,
    "start_time": "2024-12-02T16:56:28.428Z"
   },
   {
    "duration": 147780,
    "start_time": "2024-12-02T16:56:34.672Z"
   },
   {
    "duration": 148050,
    "start_time": "2024-12-02T16:59:29.213Z"
   },
   {
    "duration": 31,
    "start_time": "2024-12-02T17:03:44.400Z"
   },
   {
    "duration": 167438,
    "start_time": "2024-12-02T17:03:51.809Z"
   },
   {
    "duration": 14820,
    "start_time": "2024-12-02T17:06:46.976Z"
   },
   {
    "duration": 4215,
    "start_time": "2024-12-02T17:07:05.072Z"
   },
   {
    "duration": 4589,
    "start_time": "2024-12-02T17:07:13.721Z"
   },
   {
    "duration": 196049,
    "start_time": "2024-12-02T17:07:25.649Z"
   },
   {
    "duration": 188302,
    "start_time": "2024-12-02T17:10:48.772Z"
   },
   {
    "duration": 104559,
    "start_time": "2024-12-02T17:14:19.467Z"
   },
   {
    "duration": 0,
    "start_time": "2024-12-02T17:16:04.029Z"
   },
   {
    "duration": 95143,
    "start_time": "2024-12-02T17:16:07.020Z"
   },
   {
    "duration": 80620,
    "start_time": "2024-12-02T17:17:48.038Z"
   },
   {
    "duration": 15622,
    "start_time": "2024-12-02T17:19:13.148Z"
   },
   {
    "duration": 18824,
    "start_time": "2024-12-02T17:19:32.857Z"
   },
   {
    "duration": 146207,
    "start_time": "2024-12-02T17:19:53.754Z"
   },
   {
    "duration": 124,
    "start_time": "2024-12-02T17:22:25.784Z"
   },
   {
    "duration": 13173,
    "start_time": "2024-12-02T17:24:00.989Z"
   },
   {
    "duration": 146365,
    "start_time": "2024-12-02T17:24:17.905Z"
   },
   {
    "duration": 12,
    "start_time": "2024-12-02T17:26:49.536Z"
   },
   {
    "duration": 71796,
    "start_time": "2024-12-02T17:27:40.869Z"
   },
   {
    "duration": 6,
    "start_time": "2024-12-02T17:29:09.967Z"
   },
   {
    "duration": 6250,
    "start_time": "2024-12-02T17:30:06.508Z"
   },
   {
    "duration": 1095,
    "start_time": "2024-12-02T17:45:07.804Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-02T17:45:08.901Z"
   },
   {
    "duration": 582,
    "start_time": "2024-12-02T17:45:08.906Z"
   },
   {
    "duration": 200,
    "start_time": "2024-12-02T17:45:09.491Z"
   },
   {
    "duration": 470,
    "start_time": "2024-12-02T17:45:09.692Z"
   },
   {
    "duration": 12,
    "start_time": "2024-12-02T17:45:10.165Z"
   },
   {
    "duration": 24,
    "start_time": "2024-12-02T17:45:10.179Z"
   },
   {
    "duration": 575,
    "start_time": "2024-12-02T17:45:10.205Z"
   },
   {
    "duration": 533,
    "start_time": "2024-12-02T17:45:10.782Z"
   },
   {
    "duration": 5,
    "start_time": "2024-12-02T17:45:11.318Z"
   },
   {
    "duration": 344,
    "start_time": "2024-12-02T17:45:11.325Z"
   },
   {
    "duration": 373989,
    "start_time": "2024-12-02T17:45:11.672Z"
   },
   {
    "duration": 4804,
    "start_time": "2024-12-02T17:51:25.663Z"
   },
   {
    "duration": 69983,
    "start_time": "2024-12-02T17:51:30.469Z"
   },
   {
    "duration": 14,
    "start_time": "2024-12-02T17:52:40.455Z"
   },
   {
    "duration": 251,
    "start_time": "2024-12-02T18:00:07.968Z"
   },
   {
    "duration": 137639,
    "start_time": "2024-12-02T18:00:18.595Z"
   },
   {
    "duration": 53795,
    "start_time": "2024-12-02T18:02:39.455Z"
   },
   {
    "duration": 155860,
    "start_time": "2024-12-02T18:03:35.791Z"
   },
   {
    "duration": 220,
    "start_time": "2024-12-02T18:06:16.999Z"
   },
   {
    "duration": 4691,
    "start_time": "2024-12-02T18:06:22.665Z"
   },
   {
    "duration": 8,
    "start_time": "2024-12-02T18:08:40.749Z"
   },
   {
    "duration": 30,
    "start_time": "2024-12-02T18:15:40.856Z"
   },
   {
    "duration": 990,
    "start_time": "2024-12-02T18:16:04.979Z"
   },
   {
    "duration": 1418,
    "start_time": "2024-12-02T18:17:52.851Z"
   },
   {
    "duration": 1291,
    "start_time": "2024-12-02T18:18:12.880Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
